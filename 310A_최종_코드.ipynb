{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "310A 최종 코드.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNwLIVvjXdu/3/efewIPTql",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/310Aa/test/blob/master/310A_%EC%B5%9C%EC%A2%85_%EC%BD%94%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYpL-_8BURsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qSosOnrUX_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9  25361\n",
        "!kill -9  7370"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCgdkzNNUZ3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0namcNBxUbMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensorflow와 tf.keras를 임포트\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# 헬퍼(helper) 라이브러리를 임포트\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukb-iYh8Ucep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train x,y데이터 불러오기\n",
        "X1 = np.load('/home/ubuntu/SDL/kmy/train/chunks_160x160_NORMvsDISTRESS_50k_train_chunk_00_x.npy')\n",
        "\n",
        "Y1 = np.load('/home/ubuntu/SDL/kmy/train/chunks_160x160_NORMvsDISTRESS_50k_train_chunk_00_y.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWoAIpd0Ud5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#validation x,y데이터 불러오기\n",
        "A1 = np.load('/home/ubuntu/SDL/kmy/valid/chunks_160x160_NORMvsDISTRESS_50k_valid_chunk_0_x.npy')\n",
        "\n",
        "B1 = np.load('/home/ubuntu/SDL/kmy/valid/chunks_160x160_NORMvsDISTRESS_50k_valid_chunk_0_y.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm6_g-MDUfdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test 데이터 불러오기\n",
        "C1 = np.load('/home/ubuntu/SDL/kmy/test/chunks_160x160_NORMvsDISTRESS_50k_test_chunk_0_x.npy')\n",
        "\n",
        "D1 = np.load('/home/ubuntu/SDL/kmy/test/chunks_160x160_NORMvsDISTRESS_50k_test_chunk_0_y.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2emInOJwUhGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#데이터 자르기\n",
        "X=X1[0:999]\n",
        "Y=Y1[0:999]\n",
        "Xvalid=A1[0:199]\n",
        "Yvalid=B1[0:199]\n",
        "Xtest=C1[0:199]\n",
        "Ytest=D1[0:199]\n",
        "#데이터 shape 확인\n",
        "print(np.shape(X))\n",
        "print(np.shape(Y))\n",
        "print(np.shape(Xvalid))\n",
        "print(np.shape(Yvalid))\n",
        "print(np.shape(Xtest))\n",
        "print(np.shape(Ytest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY41PnrJUlIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#데이터 배열 바꾸기\n",
        "X=np.squeeze(X,axis=1)\n",
        "X=np.expand_dims(X,axis=3)\n",
        "\n",
        "Xvalid=np.squeeze(Xvalid,axis=1)\n",
        "Xvalid=np.expand_dims(Xvalid,axis=3)\n",
        "\n",
        "Xtest=np.squeeze(Xtest,axis=1)\n",
        "Xtest=np.expand_dims(Xtest,axis=3)\n",
        "#바꾼 배열 확인\n",
        "print(np.shape(Xvalid))\n",
        "print(np.shape(Xtest))\n",
        "print(np.shape(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul2zaoO7Um6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#데이터 augmentation (상하,좌우 반전)\n",
        "import cv2\n",
        "X2=[]\n",
        "X3=[]\n",
        "X4=[]\n",
        "for i in range(len(X)):\n",
        "    X2.append(cv2.flip(X[i], 1) ) #좌우반전\n",
        " \n",
        "for j in range(len(X)):\n",
        "    X3.append(cv2.flip(X[j], 0)) #상하반전\n",
        " \n",
        "\n",
        "for k in range(len(X2)):\n",
        "    X4.append(cv2.flip(X2[k], 0))#상하좌우\n",
        "    \n",
        "#데이터 배열 바꾸기   \n",
        "X2=np.expand_dims(X2,axis=3)\n",
        "X3=np.expand_dims(X3,axis=3)    \n",
        "X4=np.expand_dims(X4,axis=3)\n",
        "\n",
        "print(np.shape(X2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hzWBJ2OUoT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#여러 데이터 파일 하나로 합치기\n",
        "Xtrain=np.concatenate((X,X2,X3,X4), axis=0)\n",
        "Ytrain=np.concatenate((Y,Y,Y,Y), axis=0)\n",
        "print(np.shape(Xtrain))\n",
        "print(np.shape(Ytrain))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDd2oSVfUiUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GqeOiL7Uqhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 텐서플로우 버전확인\n",
        "print(tf.__version__)    \n",
        "print(keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn0Xs73mUr6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.0001  # 러닝레이트 \n",
        "training_epochs = 100  # 에폭\n",
        "batch_size = 64     # 배치사이즈"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTrcOEggUtWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#모델 쌓기\n",
        "from keras import regularizers  \n",
        "def create_model():\n",
        "    inputs = keras.Input(shape=(160,160,1))   #input\n",
        "    conv1 = keras.layers.Conv2D(filters=32, kernel_size=3, padding='SAME', activation=tf.nn.relu,kernel_regularizer = regularizers.l2(0.01),kernel_initializer = 'random_normal', bias_initializer = 'zeros')(inputs)  #레이어의 초기 임의 weight를 설정(random normal: 정규 분포로 텐서를 생성하는 이니셜 라이저), weight 정규화:(L2, 0.01), bias: 0값으로 초기화\n",
        "    conv2 = keras.layers.Conv2D(filters=32, kernel_size=3, padding='SAME', activation=tf.nn.relu,kernel_regularizer = regularizers.l2(0.01))(conv1)\n",
        "    pool1 = keras.layers.MaxPool2D(padding='SAME')(conv2)      #Maxpooling 사용\n",
        "    \n",
        "    conv3 = keras.layers.Conv2D(filters=64, kernel_size=3, padding='SAME', activation=tf.nn.relu,kernel_regularizer = regularizers.l2(0.01))(pool1)\n",
        "    conv4 = keras.layers.Conv2D(filters=64, kernel_size=3, padding='SAME', activation=tf.nn.relu,kernel_regularizer = regularizers.l2(0.01))(conv3)\n",
        "    pool2 = keras.layers.MaxPool2D(padding='SAME')(conv4)\n",
        "        \n",
        "    conv5 = keras.layers.Conv2D(filters=128, kernel_size=3, padding='SAME', activation=tf.nn.relu,kernel_regularizer = regularizers.l2(0.01))(pool2)\n",
        "    conv6 = keras.layers.Conv2D(filters=128, kernel_size=3, padding='SAME', activation=tf.nn.relu,kernel_regularizer = regularizers.l2(0.01))(conv5)\n",
        "    pool3 = keras.layers.MaxPool2D(padding='SAME')(conv6)\n",
        "   \n",
        "    conv7 = keras.layers.Conv2D(filters=256, kernel_size=3, padding='SAME', activation=tf.nn.relu,kernel_regularizer = regularizers.l2(0.01))(pool3)\n",
        "    conv8 = keras.layers.Conv2D(filters=256, kernel_size=3, padding='SAME', activation=tf.nn.relu,kernel_regularizer = regularizers.l2(0.01),name='target_conv')(conv7)\n",
        "    pool4 = keras.layers.MaxPool2D(padding='SAME')(conv8)\n",
        "    drop0 = keras.layers.Dropout(rate=0.5)(pool4)      #drop out 0.5 사용\n",
        "   \n",
        "    pool4_flat = keras.layers.Flatten()(drop0)\n",
        "    dense4 = keras.layers.Dense(units=256, activation=tf.nn.relu,kernel_regularizer = regularizers.l2(0.01))(pool4_flat)\n",
        "    drop1 = keras.layers.Dropout(rate=0.5)(dense4)           \n",
        "    dense5 = keras.layers.Dense(units=128, activation=tf.nn.relu,kernel_regularizer = regularizers.l2(0.01))(drop1) \n",
        "    drop2 = keras.layers.Dropout(rate=0.4)(dense5)           \n",
        "    logits = keras.layers.Dense(units=2,activation= 'sigmoid')(drop2) \n",
        "    return keras.Model(inputs=inputs, outputs=logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOzegvlpUu8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model= create_model()\n",
        "model.summary() # 모델에 대한 요약 출력"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPzPTHgMUwl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "\n",
        "# 모델 컴파일 진행 Adam Optimizer 사용\n",
        "model.compile(loss='sparse_categorical_crossentropy',  \n",
        "              optimizer=keras.optimizers.Adam(learning_rate=lr),               \n",
        "              metrics=['accuracy'])   \n",
        " \n",
        "# 학습실행\n",
        "history = model.fit(Xtrain, Ytrain, \n",
        "          batch_size=batch_size, \n",
        "          epochs=training_epochs, \n",
        "          verbose=1,                            # verbose는 학습 중 출력되는 문구를 설정\n",
        "          validation_data=(Xvalid, Yvalid))     \n",
        "score = model.evaluate(Xtest, Ytest, verbose=0)   # test loss 값 결과 확인\n",
        "print('test_loss :', score[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzFeeJiMU0Ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 모델 학습 후 정보가 담긴 history 내용을 선 그래프로 그림\n",
        "\n",
        "def plot_acc(history, title=None):        # 정확도 Visualization\n",
        "    # summarize history for accuracy\n",
        "    if not isinstance(history, dict):\n",
        "        history = history.history\n",
        "\n",
        "    plt.plot(history['acc'])        # training accuracy\n",
        "    plt.plot(history['val_acc'])    # validation accuracy\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.ylabel('Accracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training data', 'Validation data'], loc=0)\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "def plot_loss(history, title=None):     # Loss 값 Visualization\n",
        "    # summarize history for loss\n",
        "    if not isinstance(history, dict):\n",
        "        history = history.history\n",
        "\n",
        "    plt.plot(history['loss'])           # training loss\n",
        "    plt.plot(history['val_loss'])       # validation loss\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training data', 'Validation data'], loc=0)\n",
        "    # plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-IuO4FjU8Jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualization\n",
        "plot_acc(history, '(a) Accuracy')  # 학습 경과에 따른 정확도 변화 추이\n",
        "plt.show()\n",
        "plot_loss(history, '(b) Loss')     # 학습 경과에 따른 손실값 변화 추이\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQsavlpDU9ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(Xtest, Ytest, verbose=0) # test 정확도 값 결과 확인\n",
        "print('test-acc :', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A_jYlXAU-06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(Xtest)\n",
        "predictions[120]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdVV3fwGU_-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.argmax(predictions[111]))\n",
        "print(Ytest[111])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drbiYe0aVA-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test 데이터의 이미지들, 정답 여부와 예측 확신 퍼센트를 보여주는 함수\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    plt.imshow(np.array(np.squeeze(img)),cmap='gray')\n",
        "    if predicted_label == true_label:\n",
        "        color = 'blue'            #정확하게 예측했으면, 파란색 글씨\n",
        "    else : \n",
        "        color = 'red'             #잘못 예측했으면, 빨간색 글씨\n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label, 100*np.max(predictions_array), true_label),color=color)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-ZpmDFLVDha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#이미지, 정답 여부, 퍼센트 출력\n",
        "num_rows = 19\n",
        "num_cols = 10\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, num_cols, i+1)\n",
        "  plot_image(i, predictions, Ytest, Xtest)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik05uBMEVFeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = []\n",
        "for i in range(len(Ytest)):\n",
        "    pred.append(np.argmax(predictions[i]))\n",
        "    \n",
        "pred[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5r4vJuoVHLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix #confusion matrix 라이브러리 임포트\n",
        "\n",
        "con_mat = confusion_matrix(Ytest, pred) #confusion matrix 함수 실행\n",
        "\n",
        "TP = con_mat[1][1] #둘다 Anomal이며, 예측값이 positive(이상값)\n",
        "FN = con_mat[1][0] #실제값과 예측값이 달랐으며, 예측값이 negative(정상값)\n",
        "FP = con_mat[0][1] #실제값과 예측값이 달랐으며, 예측값이 postive(이상값)\n",
        "TN = con_mat[0][0] #둘다 nomal이며, 예측값이 negative(정상값)\n",
        "print('\\n',\n",
        "      'TP :', TP, '\\n', \n",
        "      'FN :', FN, '\\n', \n",
        "      'FP :', FP, '\\n', \n",
        "      'TN :', TN, '\\n')\n",
        "\n",
        "Accuracy = (TP+TN)/(TP+FN+FP+TN) #정분류율: 전체관측치 중 실제값과 예측치가 일치하는 정도\n",
        "print('Accuracy(정분류율=(TP+TN)/(TP+FN+FP+TN)):', '{:.2%}'.format(Accuracy))\n",
        "\n",
        "Error_rate = (FP+FN)/(TP+FN+FP+TN) #오분류율: 전체 관측치 중 실제값과 예측치가 다른 정보 (1-accuracy)\n",
        "print('Error_rate(오분류율=(FP+FN)/(TP+FN+FP+TN):', '{:.2%}'.format(Error_rate))\n",
        "\n",
        "Precirion = TP/(TP+FP) #정확도: TRUE로 예측한 관측치 중 실제값이 TRUE인 정도\n",
        "print('Precirion(정확도=TP/(TP+FP)):', '{:.2%}'.format(Precirion))\n",
        "\n",
        "Recall = TP/(TP+FN) #재현율: 실제값이 TRUE인 관측치 중 예측치가 적중한 정도, 민감도\n",
        "print('Recall(재현율,민감도=TP/(TP+FN)):', '{:.2%}'.format(Recall))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "# Confusion Matrix 표 그리기\n",
        "plt.imshow(con_mat, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "\n",
        "# Plot 구성하기\n",
        "plt.title('Confusion Matrix', fontsize=20) # Plot 이름\n",
        "plt.tight_layout()\n",
        "plt.colorbar()\n",
        "label=[\"Anomal(1)\", \"Nomal(0)\"] # 라벨값\n",
        "tick_marks = np.arange(len(label)) \n",
        "plt.xticks(tick_marks, label)\n",
        "plt.yticks(tick_marks, label)\n",
        "plt.xlabel('Predicted', fontsize=15)\n",
        "plt.ylabel('True', fontsize=15)\n",
        "\n",
        "# 표 안에 숫자 기입\n",
        "name = [['TP','FN'], ['FP', 'TN']]\n",
        "thresh = con_mat.max() / 2.\n",
        "for i in range(2):\n",
        "     for j in range(2):\n",
        "        plt.text(j, i, str(name[i][j])+\" = \"+str(con_mat[1-i, 1-j]),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if con_mat[i, j] > thresh else \"black\",\n",
        "                 fontsize=16)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoM-UOyg6Hr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Grad CAM\n",
        "gradFP=[] #grad에 비정상으로 잘못 예측한 인덱스 출력하기\n",
        "for i in range(len(pred)):\n",
        "    if (pred[i] == 1 & Ytest[i] == 0):\n",
        "        gradFP.append(i)\n",
        "print(gradFP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDE_kgYv6hPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "from keras.preprocessing import image\n",
        "import cv2\n",
        "\n",
        "num_rows = 10\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(5*num_cols, 5*num_rows))\n",
        "for i in range(num_images):    \n",
        "    plt.subplot(2*num_rows, 2*num_cols, (2*i)+1)    \n",
        "    x=Xtest[gradFP[i]]  # 예측 인덱스 \n",
        "    shape = x.shape\n",
        "    x_=x.reshape(1,shape[0],shape[1],shape[2]) \n",
        "    argmax = np.argmax(predictions[gradFP[i]])\n",
        "    output = model.output[:, argmax]     # 예측 클래스를 output으로 지정\n",
        "    last_conv_layer = model.get_layer('target_conv')    # 마지막 conv 층 불러오기\n",
        "    # input img 는 feature map \n",
        "    grads = K.gradients(output,last_conv_layer.output)[0] #loss,input_img   \n",
        "    pooled_grads = K.mean(grads, axis=(0, 1, 2))  # 특성 맵 채널별 그래디언트 평균 값이 담긴 벡터\n",
        "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]]) # 샘플 이미지가 주어졌을 때 pooled_grads와 target_conv의 특성 맵 출력을 구한다 \n",
        "    pooled_grads_value, conv_layer_output_value = iterate([x_])  # 샘플 이미지를 주입하고 두 개의 넘파이 배열을 얻는다\n",
        "    for j in range(128):\n",
        "        conv_layer_output_value[:, :, j] *= pooled_grads_value[j]     # 클래스에 대한 '채널의 중요도'를 특성 맵 배열의 채널에 곱한다 \n",
        "    heatmap = np.mean(conv_layer_output_value, axis=-1)    # 만들어진 특성 맵에서 채널 축을 따라 평균한 값이 클래스 활성화의 히트맵\n",
        "    plt.imshow(np.squeeze(Xtest[gradFP[i]]))\n",
        "    plt.subplot(2*num_rows, 2*num_cols, (2*i)+2)   \n",
        "    plt.imshow(heatmap)    #히트맵을 그려준다\n",
        "   # plt.xlabel(\"{} : {} ({})\".format(grad[i], pred[grad[i]], Ytest[grad[i]]))\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVmZInTq6hCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Grad CAM\n",
        "gradFN=[] #grad에 정상으로 잘못 예측한 인덱스 출력하기\n",
        "for i in range(len(pred)):\n",
        "    if (pred[i] == 0 & Ytest[i] == 1):\n",
        "        gradFN.append(i)\n",
        "print(gradFN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu6n0C8z6H5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "from keras.preprocessing import image\n",
        "import cv2\n",
        "\n",
        "num_rows = 10\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(5*num_cols, 5*num_rows))\n",
        "for i in range(num_images):    \n",
        "    plt.subplot(2*num_rows, 2*num_cols, (2*i)+1)    \n",
        "    x=Xtest[gradFN[i]]  # 예측 인덱스 \n",
        "    shape = x.shape\n",
        "    x_=x.reshape(1,shape[0],shape[1],shape[2]) \n",
        "    argmax = np.argmax(predictions[gradFN[i]])\n",
        "    output = model.output[:, argmax]     # 예측 클래스를 output으로 지정\n",
        "    last_conv_layer = model.get_layer('target_conv')    # 마지막 conv 층 불러오기\n",
        "    # input img 는 feature map \n",
        "    grads = K.gradients(output,last_conv_layer.output)[0] #loss,input_img   \n",
        "    pooled_grads = K.mean(grads, axis=(0, 1, 2))  # 특성 맵 채널별 그래디언트 평균 값이 담긴 벡터\n",
        "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]]) # 샘플 이미지가 주어졌을 때 pooled_grads와 target_conv의 특성 맵 출력을 구한다 \n",
        "    pooled_grads_value, conv_layer_output_value = iterate([x_])  # 샘플 이미지를 주입하고 두 개의 넘파이 배열을 얻는다\n",
        "    for j in range(128):\n",
        "        conv_layer_output_value[:, :, j] *= pooled_grads_value[j]     # 클래스에 대한 '채널의 중요도'를 특성 맵 배열의 채널에 곱한다 \n",
        "    heatmap = np.mean(conv_layer_output_value, axis=-1)    # 만들어진 특성 맵에서 채널 축을 따라 평균한 값이 클래스 활성화의 히트맵\n",
        "    plt.imshow(np.squeeze(Xtest[gradFN[i]]))\n",
        "    plt.subplot(2*num_rows, 2*num_cols, (2*i)+2)   \n",
        "    plt.imshow(heatmap)    #히트맵을 그려준다\n",
        "   # plt.xlabel(\"{} : {} ({})\".format(grad[i], pred[grad[i]], Ytest[grad[i]]))\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq5QCaamVM_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Grad CAM\n",
        "grad=[] #grad에 비정상으로 맞게 예측한 인덱스 출력하기\n",
        "for i in range(len(pred)):\n",
        "    if (pred[i] == 1 & Ytest[i] == 1):\n",
        "        grad.append(i)\n",
        "print(grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMwIjAFNVNli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "from keras.preprocessing import image\n",
        "import cv2\n",
        "\n",
        "num_rows = 10\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(5*num_cols, 5*num_rows))\n",
        "for i in range(num_images):    \n",
        "    plt.subplot(2*num_rows, 2*num_cols, (2*i)+1)    \n",
        "    x=Xtest[grad[i]]  # 예측 인덱스 \n",
        "    shape = x.shape\n",
        "    x_=x.reshape(1,shape[0],shape[1],shape[2]) \n",
        "    argmax = np.argmax(predictions[grad[i]])\n",
        "    output = model.output[:, argmax]     # 예측 클래스를 output으로 지정\n",
        "    last_conv_layer = model.get_layer('target_conv')    # 마지막 conv 층 불러오기\n",
        "    # input img 는 feature map \n",
        "    grads = K.gradients(output,last_conv_layer.output)[0] #loss,input_img   \n",
        "    pooled_grads = K.mean(grads, axis=(0, 1, 2))  # 특성 맵 채널별 그래디언트 평균 값이 담긴 벡터\n",
        "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]]) # 샘플 이미지가 주어졌을 때 pooled_grads와 target_conv의 특성 맵 출력을 구한다 \n",
        "    pooled_grads_value, conv_layer_output_value = iterate([x_])  # 샘플 이미지를 주입하고 두 개의 넘파이 배열을 얻는다\n",
        "    for j in range(128):\n",
        "        conv_layer_output_value[:, :, j] *= pooled_grads_value[j]     # 클래스에 대한 '채널의 중요도'를 특성 맵 배열의 채널에 곱한다 \n",
        "    heatmap = np.mean(conv_layer_output_value, axis=-1)    # 만들어진 특성 맵에서 채널 축을 따라 평균한 값이 클래스 활성화의 히트맵\n",
        "    plt.imshow(np.squeeze(Xtest[grad[i]]))\n",
        "    plt.subplot(2*num_rows, 2*num_cols, (2*i)+2)   \n",
        "    plt.imshow(heatmap)    #히트맵을 그려준다\n",
        "   # plt.xlabel(\"{} : {} ({})\".format(grad[i], pred[grad[i]], Ytest[grad[i]]))\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}